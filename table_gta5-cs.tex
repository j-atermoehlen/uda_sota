\resizebox{\textwidth}{!}{%
\begin{tabular}{cc@{\hspace{1em}}c@{\hspace{1em}}cccccccccccccccccc@{\hspace{1em}}cc}
		\toprule
		\multicolumn{22}{c}{\textbf{\colorbox{tu21}{GTA5\vphantom{y}} $\longrightarrow$ \colorbox{tu41}{Cityscapes}}}\\
		\midrule
		\multirow{1}{*}{\textbf{Model}} & \multirow{1}{*}{\textbf{Feat. Ex.}} & \multicolumn{19}{c}{\textbf{Class IoU}} & \multirow{1}{*}{\textbf{mIoU}} & \multirow{1}{*}{\textbf{Code}} \\
		%\midrule
		 &  &  \rot{Road} &  \rot{Sidewalk} &  \rot{Building} &  \rot{Wall} &  \rot{Fence} &  \rot{Pole} &  \rot{T. Light} &  \rot{T. Sign} &  \rot{Veg.} &  \rot{Terrain} &  \rot{Sky} &  \rot{Person} &  \rot{Rider} &  \rot{Car} &  \rot{Truck} &  \rot{Bus} &  \rot{Train} &  \rot{M.bike} &  \rot{Bicycle} & & \\
		\midrule\\[-1em]
		SIBAN~\cite{Luo2019}			   & VGG-16     & 83.4 & 13.0 & 77.8 & 20.4 & 17.5 & 24.6 & 22.8 & 9.6  & 81.3 & 29.6 & 77.3 & 42.7 & 10.9 & 76.0 & 22.8 & 17.9 & 5.7  & 14.2 & 2.0  & 34.2 & - \\\\[-1em]
		CyCADA~\cite{Hoffman2018}          & VGG-16     & 85.2 & 37.2 & 76.5 & 21.8 & 15.0 & 23.8 & 22.9 & 21.5 & 80.5 & 31.3 & 60.7 & 50.5 & 9.0  & 76.9 & 17.1 & 28.2 & 4.5  & 9.8  & 0.0  & 35.4 & \href{https://github.com/jhoffman/cycada_release}{\checkmark} \\\\[-1em]
		DCAN~\cite{Wu2018a}                & VGG-16     & 82.3 & 26.7 & 77.4 & 23.7 & 20.5 & 20.4 & 30.3 & 15.9 & 80.9 & 25.4 & 69.5 & 52.6 & 11.1 & 79.6 & 24.9 & 21.2 & 1.3  & 17.0 & 6.7  & 36.2 & \href{http://zxwu.azurewebsites.net/dcan.zip}{\checkmark}\\\\[-1em]
		MADAN~\cite{Zhao2019a}             & VGG-16     & 86.2 & 37.7 & 79.1 & 20.1 & 17.8 & 15.5 & 14.5 & 21.4 & 78.5 & -    & 73.4 & 49.7 & 16.8 & 77.8 & -    & 28.3 & -    & 17.7 & 27.5 & 41.4 & \href{https://github.com/Luodian/MADAN}{\checkmark}\\\\[-1em]
		SIM~\cite{Wang2020}				   & VGG-16     & 88.1 & 35.8 & 83.1 & 25.8 & 23.9 & 29.2 & 28.8 & 28.6 & 83.0 & 36.7 & 82.3 & 53.7 & 22.8 & 82.3 & 26.4 & 38.6 & 0.0  & 19.6 & 17.1 & 42.4 & \href{https://github.com/SHI-Labs/Unsupervised-Domain-Adaptation-with-Differential-Treatment}{\checkmark}\\\\[-1em]	
		{FDA-MBT}~\cite{Yang2020}          & VGG-16 & 86.1 & 35.1 & 80.6 & 30.8 & 20.4 & 27.5 & 30.0 & 26.0 & 82.1 & 30.3 & 73.6 & 52.5 & 21.7 & 81.7 & 24.0 & 30.5 & 29.9 & 14.6 & 24.0 & 42.2 & \href{https://github.com/YanchaoYang/FDA}{\checkmark}\\\\[-1em]
		{LTIR}~\cite{Kim2020}          & VGG-16 & 92.5 & 54.5 & 83.9 &  34.5 & 25.5 & 31.0 & 30.4 & 18.0 & 84.1 & 39.6 & 83.9 & 53.6 & 19.3 & 81.7 & 21.1 & 13.6 & 17.7 & 12.3 & 6.5 & 42.3 & \href{https://github.com/MyeongJin-Kim/Learning-Texture-Invariant-Representation}{\checkmark}\\\\[-1em]
		TGCF-DA + SE~\cite{Choi2019}	   & VGG-16     & 90.2 & 51.5 & 81.1 & 15.0 & 10.7 & 37.5 & 35.2 & 28.9 & 84.1 & 32.7 & 75.9 & 62.7 & 19.9 & 82.6 & 22.9 & 28.3 & 0.0  & 23.0 & 25.4 & 42.5 & -\\\\[-1em]


		\midrule\\[-1em]
		
		
		DCAN~\cite{Wu2018a}                & ResNet-101 & 88.5 & 37.4 & 79.3 & 24.8 & 16.5 & 21.3 & 26.3 & 17.4 & 80.8 & 30.9 & 77.6 & 50.2 & 19.2 & 77.7 & 21.6 & 27.1 & 2.70 & 14.3 & 18.1 & 38.5 & \href{http://zxwu.azurewebsites.net/dcan.zip}{\checkmark}\\\\[-1em]
		DLOW~\cite{Gong2019}               & ResNet-101 & 87.1 & 33.5 & 80.5 & 24.5 & 13.2 & 29.8 & 29.5 & 26.6 & 82.6 & 26.7 & 81.8 & 55.9 & 25.3 & 78.0 & 33.5 & 38.7 & 0.0  & 22.9 & 34.5 & 42.3 & \href{https://github.com/ETHRuiGong/DLOW}{\checkmark}\\\\[-1em]
		SIBAN~\cite{Luo2019}			   & ResNet-101 & 88.5 & 35.4 & 79.5 & 26.3 & 24.3 & 28.5 & 32.5 & 18.3 & 81.2 & 40.0 & 76.5 & 58.1 & 25.8 & 82.6 & 30.3 & 34.4 & 3.4  & 21.6 & 21.5 & 42.6 & - \\\\[-1em]
		CyCADA~\cite{Hoffman2018,Li2019b}  & ResNet-101 & 86.7 & 35.6 & 80.1 & 19.8 & 17.5 & 38.0 & 39.9 & 41.5 & 82.7 & 27.9 & 73.6 & 64.9 & 19.0 & 65.0 & 12.0 & 28.6 & 4.5  & 31.1 & 42.0 & 42.7 & \checkmark \href{https://github.com/jhoffman/cycada_release}{\cite{Hoffman2018}} \href{https://github.com/liyunsheng13/BDL}{\cite{Li2019b}}\\\\[-1em]
		SWD~\cite{Lee2019}                 & ResNet-101 & 92.0 & 46.4 & 82.4 & 24.8 & 24.0 & 35.1 & 33.4 & 34.2 & 83.6 & 30.4 & 80.9 & 56.9 & 21.9 & 82.0 & 24.4 & 28.7 & 6.1  & 25.0 & 33.6 & 44.5 & \href{https://github.com/apple/ml-cvpr2019-swd}{\checkmark}\\\\[-1em]
		ADVENT~\cite{Vu2019}               & ResNet-101 & 89.4 & 33.1 & 81.0 & 26.6 & 26.8 & 27.2 & 33.5 & 24.7 & 83.9 & 36.7 & 78.8 & 58.7 & 30.5 & 84.8 & 38.5 & 44.5 & 1.7  & 31.6 & 32.4 & 45.5 & \href{https://github.com/valeoai/ADVENT}{\checkmark} \\\\[-1em]
		{IntraDA}~\cite{Pan2020}               & ResNet-101 & 90.6 & 37.1 & 82.6 & 30.1 & 19.1 & 29.5 & 32.4 & 20.6 & 85.7 & 40.5 & 79.7 & 58.7 & 31.1 & 86.3 & 31.1 & 86.3 & 0.0 & 30.2 & 35.8 & 46.3 & \href{https://github.com/feipan664/IntraDA}{\checkmark} \\\\[-1em]
		
	{MSL}~\cite{Chen2019c}               & ResNet-101 & 89.4 & 43.0 & 82.1 & 30.5 & 21.3 & 30.3 & 34.7 & 24.0 & 85.3 & 39.4 & 78.2 & 63.0 & 22.9 & 84.6 & 36.4 & 43.0 & 5.5 & 34.7 & 33.5 & 46.4 & \href{https://github.com/ZJULearning/MaxSquareLoss}{\checkmark} \\\\[-1em]		
		
		PANDA~\cite{Hu2020}				   & ResNet-101 & 92.4 & 51.3 & 82.9 & 31.8 & 24.9 & 32.6 & 35.8 & 20.4 & 84.5 & 38.7 & 79.8 & 60.0 & 25.8 & 85.1 & 33.7 & 44.1 & 9.0  & 27.5 & 22.6 & 46.5 & -\\\\[-1em]  
		BDL~\cite{Li2019b}                 & ResNet-101 & 91.0 & 44.7 & 84.2 & 34.6 & 27.6 & 30.2 & 36.0 & 36.0 & 85.0 & 43.6 & 83.0 & 58.6 & 31.6 & 83.3 & 35.3 & 49.7 & 3.3  & 28.8 & 35.6 & 48.5 & \href{https://github.com/liyunsheng13/BDL}{\checkmark}\\\\[-1em]
		SIM~\cite{Wang2020}                & ResNet-101 & 90.6 & 44.7 & 84.8 & 34.3 & 28.7 & 31.6 & 35.0 & 37.6 & 84.7 & 43.3 & 85.3 & 57.0 & 31.5 & 83.8 & 42.6 & 48.5 & 1.9  & 30.4 & 39.0 & 49.2 & \href{https://github.com/SHI-Labs/Unsupervised-Domain-Adaptation-with-Differential-Treatment}{\checkmark}\\\\[-1em]
		CAG-UDA~\cite{Zhang2019e}          & ResNet-101 & 90.4 & 51.6 & 83.8 & 34.2 & 27.8 & 38.4 & 25.3 & 48.4 & 85.4 & 38.2 & 78.1 & 58.6 & 34.6 & 84.7 & 21.9 & 42.7 & 41.1 & 29.3 & 37.2 & 50.2 & \href{https://github.com/luanyunteng/pytorch-be-your-own-teacher}{\checkmark}\\\\[-1em]
		{LTIR}~\cite{Kim2020}          & ResNet-101 & 92.9 & 55.0 &  85.3 & 34.2 & 31.1 & 34.9 & 40.7 & 34.0 & 85.2 & 40.1 & 87.1 & 61.0 & 31.1 & 82.5 & 32.3 &   42.9 &  0.3 & 36.4 & 46.1 & 50.2 & \href{https://github.com/MyeongJin-Kim/Learning-Texture-Invariant-Representation}{\checkmark}\\\\[-1em]
		{FDA-MBT}~\cite{Yang2020}          & ResNet-101 & 92.5 & 53.3 & 82.4 & 26.5 & 27.6 & 36.4 & 40.6 & 38.9 & 82.3 & 39.8 & 78.0 & 62.6 & 34.4 & 84.9 & 34.1 & 53.1 & 16.9 & 27.7 & 46.4 & 50.45 & \href{https://github.com/YanchaoYang/FDA}{\checkmark}\\\\[-1em]
		
		\midrule\\[-1em]
		CyCADA~\cite{Hoffman2018}          & DRN-26     & 79.1 & 33.1 & 77.9 & 23.4 & 17.3 & 32.1 & 33.3 & 31.8 & 81.5 & 26.7 & 69.0 & 62.8 & 14.7 & 74.5 & 20.9 & 25.6 & 6.9 & 18.8 & 20.4 & 39.5 & \href{https://github.com/jhoffman/cycada_release}{\checkmark}\\\\[-1em]
		CrDoCo~\cite{Chen2019a}            & DRN-26     & 95.1 & 49.2 & 86.4 & 35.2 & 22.1 & 36.1 & 40.9 & 29.1 & 85.0 & 33.1 & 75.8 & 67.3 & 26.8 & 88.9 & 23.4 & 19.3 & 4.3 & 25.3 & 13.5 & 45.1 & \href{https://github.com/YunChunChen/CrDoCo-pytorch}{$(\checkmark)$}\\\\[-1em]
		\bottomrule           
	\end{tabular}
	}